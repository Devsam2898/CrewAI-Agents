{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8779345,"sourceType":"datasetVersion","datasetId":5276886},{"sourceId":8782478,"sourceType":"datasetVersion","datasetId":5279300}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Upgrade pip\n!pip install --upgrade pip\n\n# Install necessary packages\n!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29 langchain-anthropic keras-core\n\n# Install specific versions to resolve conflicts\n!pip install numpy==1.24.0 aiohttp>=3.9.2\n!pip install shapely==2.0.1 numpy==1.26.4\n!pip install cupy-cuda11x==12.0.0 cubinlinker ptxcompiler\n!pip install tensorflow==2.15.0 keras==2.15.0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h0lo_11TBOwW","outputId":"8f1615a5-1b97-4d5b-c800-0e24ba1b1f3b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install anthropic llama_parse --upgrade crewai-tools","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"id":"ZjvN30m8BWCn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from crewai import Agent, Task, Crew","metadata":{"id":"KcIWbaE1CQq-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nclaude_key = user_secrets.get_secret(\"Anthropic-Key\")\ncohere_key = user_secrets.get_secret(\"Cohere\")","metadata":{"id":"IypKDMEtDxL9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Agent\nimport os\nfrom crewai_tools import tool\nfrom langchain_anthropic import ChatAnthropic\nimport cohere\n\nco = cohere.Client(cohere_key)","metadata":{"id":"8qR62nl3CTXI","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import requests\nfrom crewai_tools import PDFSearchTool","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Set the environment variables directly in the notebook\nos.environ[\"ANTHROPIC_API_KEY\"] = \"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\"\nos.environ[\"COHERE_API_KEY\"] = \"OGBMJkM4imPhcIYZdPGarD0tSkitHByfi0zD8HRb\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tool = PDFSearchTool(\n    config=dict(\n        llm=dict(\n            provider=\"anthropic\",\n            config=dict(\n                model=\"claude-3-5-sonnet-20240620\",\n                temperature=0.7,\n                top_p=1,\n                stream=True,\n                api_key=os.getenv(\"ANTHROPIC_API_KEY\")\n            ),\n        ),\n        embedder=dict(\n            provider=\"cohere\",\n            config=dict(\n                model=\"embed-english-v3.0\",\n                api_key=os.getenv(\"COHERE_API_KEY\")  # Correctly set the Cohere API key\n            ),\n        ),\n    )\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from langchain_anthropic import ChatAnthropic\n\nmy_llm = ChatAnthropic(\n    model=\"claude-3-5-sonnet-20240620\",\n    temperature=0,\n    max_tokens=1024,\n    timeout=None,\n    max_retries=2,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parser_agent = Agent(\n    role='Document Parser',\n    goal='Parse and analyze documents using LlamaParse',\n    backstory='You are an expert in document analysis, capable of parsing complex PDFs and extracting meaningful information using LlamaParse.',\n    tools=[tool],\n    llm=my_llm\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"researcher_agent = Agent(\n    role='Researcher',\n    goal=\"Your goal is to research thoroughly on questions from {file_path} \"\n         \"about anything that user \"\n         \"requires with the help of tools provided.\",\n    backstory = \"This agent specializes in conductinng research, \"\n                \"where the research work is spanning from Graduate Level Reasoning, Undergraduate level knowledge, \"\n                \"to Grade School Math. Your Job is to provide detail research to evaluator_agent.\",\n    llm= my_llm,\n    tools = [tool],\n    verbose = True,\n    allow_delegation = True\n)","metadata":{"id":"ni1Yxt3Dy7vB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define an agent that uses the YouTube tool\nevaluator_agent = Agent(\n    role='Evaluator',\n    goal=\"Your goal is to achieve perfection in evaluating the research provided by research_agent, \"\n         \"on {file_path} questions.\",\n    backstory = \"You are equipped with vaious tools and knowledge for you to evaluate, \"\n                \"data provided to you by research_agent and nullify anything which is not, \"\n                \"related to topic user has provided.\",\n    llm=my_llm,\n    tools=[tool],\n    verbose = True,\n    allow_delegation = True\n)","metadata":{"id":"3deBUk9qrFkF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tutor_agent = Agent(\n    role='Tutor',\n    tools = [tool],\n    goal=\"Your primary goal is to explain the concepts regarding {file_path} in simple words for better \"\n         \"understanding of the topic and increasing user's knowledge.\",\n    backstory = \"You have been feeded with the thoroughly evaluated the process of solving any problems, \"\n                \"or any information the evaluator_agent provides you. Your will explain the process which incudes, \"\n                \"understanding of the problem, ways to tackle the problem, simple tricks to make the hard problems simplify, \"\n                \"steps you go through for the answer and the answer itself so that user can understand the topic efficiently.\",\n    llm=my_llm,\n    verbose = True,\n    allow_delegation = True\n)","metadata":{"id":"w0zg0miyrI8x","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parsing_task = Task(\n    description=\"Upload and parse the {file_path} PDF document using LlamaParse. Extract and return the content in Markdown format.\",\n    expected_output=\"The parsed content of the PDF document in Markdown format.\",\n    tools=[tool],\n    agent=parser_agent\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Task for Data Analyst Agent: Analyze Market Data\nresearcher_task = Task(\n    description=(\n        \"Monitor and research data user asks for in the field of topics related to {file_path}.\"\n    ),\n    expected_output=(\n        \"Insights and detail information on the {file_path} related topics.\"\n    ),\n    agent=researcher_agent,\n)","metadata":{"id":"vgrqjy1m510Z","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Task for Data Analyst Agent: Analyze Market Data\nevaluator_task = Task(\n    description=(\n        \"Continuously monitor,analyze and evaluate the data accumulated by research_tasks\"\n        \"Use statistical modeling and machine learning to solve, fulfill knowledge \"\n        \"demand of the user.\"\n    ),\n    expected_output=(\n        \"The output should be precise, apt, to the point and absolutely correct informationwhich \"\n        \"will be provided to the tutor_task.\"\n    ),\n    agent=evaluator_agent,\n)","metadata":{"id":"kbiONwbG51xE","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Task for Data Analyst Agent: Analyze Market Data\ntutor_task = Task(\n    description=(\n        \"Explain the refined answer in simple words obtained from the evaluator_agent\"\n    ),\n    expected_output=(\n        \"Detailed analysis of the problem, it's explanation and the answer for the user to understand the topic in depth.\"\n    ),\n    agent=tutor_agent,\n)","metadata":{"id":"6yxENlfb51u-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from crewai import Process\n# Define the crew with agents and tasks\nuniverity_crew = Crew(\n    agents=[parser_agent,\n            researcher_agent,\n            evaluator_agent,\n            tutor_agent],\n\n    tasks=[parsing_task,\n           researcher_task,\n           evaluator_task,\n           tutor_task],\n\n    manager_llm=my_llm,\n    process=Process.hierarchical,\n    verbose=True\n)","metadata":{"id":"DDafZRKz51sY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example data for kicking off the process\nuniversity_education_inputs = {\n    'file_path': '/kaggle/input/mit-questions-only-pdf/MIT_qs.pdf',\n}","metadata":{"id":"zzNf1O6W51qG","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = univerity_crew.kickoff(inputs=university_education_inputs)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":445},"id":"ebD_4f_451nq","outputId":"01250f74-1d12-4580-c951-7ee0b0026a70","trusted":true},"execution_count":null,"outputs":[]}]}